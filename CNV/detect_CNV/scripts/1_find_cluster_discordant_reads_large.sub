# submit a job node to perform discordant read-pair detection and clustering (step 1) within each sample/across all samples

### this is a single job that uses large input data
# Files for the below lines MUST all be somewhere within /home/username,
# and not within /staging/username

initialdir = $(dir_out)/$(sample)
executable = $(dir_scripts)/1_find_cluster_discordant_reads_large.sh
arguments = "$(sample) $(contig) $(conda_pack_squid) $(insert_size_cutoff) $(insertSizeDiffCutoff) $(job) $(path_in_stage)"
log = $(job).log
output = $(job).out
error = $(job).err
when_to_transfer_output = ON_EXIT_OR_EVICT

## Do NOT list the large data files here
transfer_input_files = $(conda_pack_squid), $(software_pack)
should_transfer_files = YES

# # IMPORTANT! Require execute servers that can access /staging
Requirements = (Target.HasCHTCStaging == true)

# add this flag for jobs expected to run for longer than 72 hours
# do not use the +LongJob flag unnecessarily or without consulting the Research Computing Facilitators. 
# When this flag is applied in other cases, it can make a job take longer to start 
+LongJob = true

# Make sure to still include lines like "request_memory", "request_disk", "request_cpus", etc. 
+WantFlocking = false
+WantGlideIn = false
request_cpus = $(request_cpus)
request_disk = $(request_disk)
request_memory = $(request_memory)
queue